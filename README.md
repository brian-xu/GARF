


<p align="center">
  <h1 align="center"> <img src="assets/cat.png" alt="Cambrian" width="23" height="auto"> GARF: Learning Generalizable 3D Reassembly </br> for Real-World Fractures </h1>
  <p align="center">
  A generalizable flow matching-based 3D reassembly method trained on 1.9 Million fractures, enabling precise real-world fragment pose alignment. ðŸ˜Šacross extensive benchmarks, concise code with efficient performance.
  </p>
  <p align="center">
    <a href="https://jytime.github.io/data/VGGT_CVPR25.pdf" target="_blank" rel="noopener noreferrer">
    <img src="https://img.shields.io/badge/Paper-VGGT" alt="Paper PDF">
    </a>
    <a href="https://arxiv.org/abs/2503.11651"><img src="https://img.shields.io/badge/arXiv-2503.11651-b31b1b" alt="arXiv"></a>
    <a href="https://vgg-t.github.io/"><img src="https://img.shields.io/badge/Project_Page-green" alt="Project Page"></a>
    <a href='https://huggingface.co/spaces/facebook/vggt'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue'></a>
  </p>
  <p align="center">
    <a href="https://scholar.google.com/citations?user=90IoeJsAAAAJ">Sihang Li*</a>
    Â·
    <a href="https://github.com/JDScript">Zeyu Jiang*</a>
    Â·
    <a href="https://www.linkedin.com/in/grace-chen-37a974293/">Grace Chenâ€ </a>
    Â·
    <a href="https://uk.linkedin.com/in/chenyang-xu-755125181">Chenyang Xuâ€ </a>
    Â·
    <a href="https://github.com/kevintsq">Siqi Tan</a>
    Â·
    <a href="https://github.com/kevintsq">Xue Wang</a>
    Â·
    <a href="https://irvingf7.github.io/">Irving Fang</a>
    Â·
    <a href="https://scholar.google.com/citations?user=aEmILscAAAAJ&hl=en">Kristof Zyskowski</a>
    Â·
    <a href="https://scholar.google.com/citations?user=lo1VSPUAAAAJ&hl=en">Shannon McPherron</a>
    Â·
    <a href="https://scholar.google.com/citations?user=JqLHsvYAAAAJ&hl=en">Radu Iovita</a>
    Â·
    <a href="https://scholar.google.com/citations?hl=en&user=YeG8ZM0AAAAJ">Chen Fengâœ‰</a>
    Â·
    <a href="https://jingz6676.github.io/">Jing Zhangâœ‰</a>
  </p>
  <p align="center">
    *, â€  Equal contribution âœ‰ Corresponding author

<p align="center">
    <img src="assets/main.png" alt="Main Figure" width="100%" />
</p>

  <div align="center"></div>

</p>


## News ðŸš€ðŸš€ðŸš€
- `2025/01/29`: We release the [GARF](https://huggingface.co/collections/IPEC-COMMUNITY/foundation-vision-language-action-model-6795eb96a9c661f90236acbb), which achieves state-of-the-art performance across a diverse range of synthetic and real-world benchmarks. Try our [demo](https://garf-demo.pages.dev/) on your own data! 

## ðŸ“– Table of Contents

- [ðŸ“„ Document](#Document)
- [ðŸ¤— Model Zoo](#data-preparation)
- [âœ… Evaluation Performance](#Performance)
- [ðŸ™‹ FAQs](#faq)
- [Citation](#citation)
- [License](#license)


















  <!-- ```bibtex
    @inproceedings{li2025garf,
    title={VGGT: Visual Geometry Grounded Transformer},
    author={Wang, Jianyuan and Chen, Minghao and Karaev, Nikita and Vedaldi, Andrea and Rupprecht, Christian and Novotny, David},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year={2025}
    }
``` -->